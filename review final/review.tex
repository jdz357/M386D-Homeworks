\documentclass[letterpaper,twoside,12pt]{article}
\usepackage{a4wide,graphicx,fancyhdr,clrscode,tabularx,amsmath,amssymb,amsfonts,color,enumitem, bm, bbm, array, textcomp, subcaption, color, listings, chemformula, tcolorbox, setspace, xcolor, hyperref}
\usepackage{amsthm}		%theorem style 
%\usepackage{geometry}  %Adjust margins if needed. 
%\geometry{margin=1.25in} 
%\usepackage{mathptmx}      %SET MATH TYPE FONT TO TIMES NEW ROMAN
%These lines make the theorem NAME BOLD
\newtheoremstyle{mystyle}%                % Name
  {}%                                     % Space above
  {}%                                     % Space below
  {\itshape}%                                     % Body font
  {}%                                     % Indent amount
  {\bfseries}%                            % Theorem head font
  {.}%                                    % Punctuation after theorem head
  { }%                                    % Space after theorem head, ' ', or \newline
  {\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}%                                     % Theorem head spec (can be left empty, meaning `normal')
\theoremstyle{mystyle}
\newtheorem{theorem}{Theorem}[section]
%end of making theorem name bold. 
\newtheorem*{thm}{Theorem}		%Theorem no number. 
\newtheorem{definition}{Definition}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem*{lemm}{Lemma}
\newtheorem{slem}{Sub-Lemma}
\newtheorem{prop}{Proposition}[section]
\newtheorem*{propp}{Proposition}
\newtheorem*{ex}{Example}
\newtheorem*{example}{Example}
\newtheorem{notee}{Note}[section]
\newtheorem*{note}{Note}
\usepackage[super]{nth}
\usepackage[makeroom]{cancel}

%----------------------- Macros and Definitions --------------------------
\setlength{\fboxsep}{2.5\fboxsep}
%Sets boxlength size

\setlength\headheight{15pt}
\addtolength\topmargin{-25pt}
\addtolength\footskip{0pt}

\fancypagestyle{plain}{%
\fancyhf{}
\fancyhead[LO,RE]{\sffamily UT Austin}
\fancyhead[RO,LE]{\sffamily CSE 386D}
\fancyfoot[LO,RE]{\sffamily Oden Institute}
\fancyfoot[RO,LE]{\sffamily\bfseries\thepage} 
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[RO,LE]{\sffamily CSE 386D}
\fancyhead[LO,RE]{\sffamily UT Austin}
\fancyfoot[LO,RE]{\sffamily Oden Institute}
\fancyfoot[RO,LE]{\sffamily\bfseries\thepage}
\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{0pt}
\newcommand{\R}{{\mathbb R}}
\newcommand{\N}{{\mathbb N}}
\newcommand{\Z}{{\mathbb Z}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\C}{{\mathbb C}}
\newcommand{\SL}{{\mathcal{L}}}
\newcommand{\DD}{\mathcal D}
\newcommand{\ScS}{\mathcal S}
\newcommand{\Om}{\Omega}
\DeclareMathOperator*{\slim}{s-lim}
\newcommand{\cg}{\color{gray}}
\newcommand{\cbk}{\color{black}}
\newcommand{\cred}{\color{red}}
\newcommand{\cblu}{\color{blue}}
\newcommand{\ve}{\varepsilon}
\usepackage{libertine}            %% For fancy font
\begin{document}
%\fontfamily{ptm}\selectfont     %% TO SELECT THE FONT
\title{\vspace{-2\baselineskip} 
Review
}
\author{Jonathan Zhang}
\date{}
\maketitle

%\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
%  \begin{theorem}
%    Here, we use the following notation: $\left( {{M^\alpha }f} \right)\left( x \right) = {x^\alpha }f\left( x \right)$.
%    
%    If $T\in \ScS'$ and $f \in \ScS$, then $T\ast f$ is smooth and polynomially bounded. 
%  \end{theorem}
%  \end{tcolorbox} 

\section{Differential Calculus in Banach Spaces and the Calculus of Variations}
\subsection{Differentiation}

  Our goal will be to generalize the notion of the 1D derivative, in the context of results like the Mean Value Theorem and Taylor's Theorem. Let us start with what we know: the standard 1D definition of the derivative is
  \begin{equation}
    f'(x) = \lim_{h\to 0} \frac{f(x+h) - f(x)}{h},
  \end{equation}
  but it is not clear how $1/h$ will generalize in higher dimensions. Indeed, it makes no sense. We can, however, define a similar concept. 
  \begin{definition}[Little o]
    Let $X, Y$ be NLS's, $f : X \to Y$. If 
    \[\lim_{h \to 0} \frac{\|f(h)\|_Y}{\|h\|_X} = 0,\]
    we say that $f$ is ``little oh'' of $h$ and write 
    \[\|f(h)\|_Y = o\left( \|h\|_X \right).\]
  \end{definition}
  \cg
    Here, we have generalized the notion of $1/h$ to multiple dimensions by looking only at the norm of the increment and of the output. 
  \cbk
  We can now formulate a notion of the derivative.
  \begin{definition}[Fr\'echet Derivative]
    Let $X, Y$ NLS, $U\subset X$ open, $f: U \to Y$. We say that $f$ is Fr\'echet differentiable (or strongly differentiable) at a point $x \in U$ if and only if there exists a bounded linear map $A \in B(X, Y)$ such that the remainder
    \[R(x,h) := f(x+h) - f(x) - Ah\]
    is $o\left( \|h\|_X \right)$. That is, 
    \[\lim_{h\to 0}\frac{\|R(x,h)\|_Y}{\|h\|_X} = 0.\]
  \end{definition}
  If $A$ exists, we call $A$ the Fr\'echet derivative of $f$ at $x$, denoted $Df(x)$. Note that by construction, $A = Df(x)$ is a linear operator on $h$. 
  The definition of the Fr\'echet derivative is consistent with the one dimensional analogue. For $f \in C^1 (\R)$, 
  \begin{equation}
    R\left( {x,h} \right) = f\left( {x + h} \right) - f\left( x \right) - f'\left( x \right)h = \left[ {\frac{{f\left( {x + h} \right) - f\left( x \right)}}{h} - f'\left( x \right)} \right]h,
  \end{equation}
  and 
  \begin{equation}
    \mathop {\lim }\limits_{h \to 0} \frac{{\left| {R\left( {x,h} \right)} \right|}}{{\left| h \right|}} = \mathop {\lim }\limits_{h \to 0} \left[ {\frac{{f\left( {x + h} \right) - f\left( x \right)}}{h} - f'\left( x \right)} \right] = 0.
  \end{equation}
  More generally, the map $Df$ (as contrasted with $Df(x)$) can be regarded as a map $Df: U\times X \ni (x, h) \to Df(x)h \in Y$. 
  \begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
    \begin{prop}
      If $f$ is Fr\'echet differentiable, then $Df(x)$ is unique, and $f$ is continuous at $x$. Moreover, if $g$ is Fr\'echet differentiable, then for every $\alpha, \beta \in \mathbb F$, 
      \[D\left( \alpha f + \beta g \right)(x) = \alpha Df(x) + \beta Dg(x).\]
      (That is to say, the operator $D$ taking functions $f \mapsto Df$ is linear.) 
    \end{prop}
  \end{tcolorbox}
  \begin{proof}
    Suppose that there are two derivatives at $x$, $A, B \in B(X, Y)$. Define the two remainders
    \begin{equation}
      \begin{gathered}
        {R_A}\left( {x,h} \right) = f\left( {x + h} \right) - f\left( x \right) - Ah \hfill \\[.2cm]
        {R_B}\left( {x,h} \right) = f\left( {x + h} \right) - f\left( x \right) - Bh. 
      \end{gathered} 
    \end{equation}
    By assumption, both $R_A(x,h) = o\left( \|h\|_X \right)$ and $R_B(x, h) = o\left( \|h\|_X \right)$. Now we show that in fact, $A = B$. 
    \begin{equation}
      \begin{split}
        {\left\| {A - B} \right\|_{B\left( {X,Y} \right)}} &= \cred \mathop {\sup }\limits_{\left\| h \right\| = \varepsilon }\cbk  \frac{{{{\left\| {Ah - Bh} \right\|}_Y}}}{{{{\left\| h \right\|}_X}}} \hfill \\[.2cm]
        &= \mathop {\sup }\limits_{\left\| h \right\| = \varepsilon } \frac{{{{\left\| {Ah - Bh} \right\|}_Y}}}{{{{\left\| h \right\|}_X}}} \hfill \\[.2cm]
        &= \mathop {\sup }\limits_{\left\| h \right\| = \varepsilon } \frac{{{{\left\| {{R_A}\left( {x,h} \right) - {R_B}\left( {x,h} \right)} \right\|}_Y}}}{{{{\left\| h \right\|}_X}}} \hfill \\[.2cm]
        &\leqslant \mathop {\sup }\limits_{\left\| h \right\| = \varepsilon } \frac{{{{\left\| {{R_A}\left( {x,h} \right)} \right\|}_Y}}}{{{{\left\| h \right\|}_X}}} + \mathop {\sup }\limits_{\left\| h \right\| = \varepsilon } \frac{{{{\left\| {{R_B}\left( {x,h} \right)} \right\|}_Y}}}{{{{\left\| h \right\|}_X}}} .
      \end{split}
    \end{equation}
    \cred Is this the right definition of the norm on $B(X,Y)$? \cbk The RHS can be made small as $\ve \to 0$. \cred Really? I thought the operator norm doesn't depend on this...\cbk Indeed, the argument of the supremum goes to zero as $\|h\| \to 0$ by the $o(\|h\|_X)$ assumption. Thus, $A = B = Df(x)$ is unique. 
    To prove that $f$ is continuous at $x$, we have 
    \begin{equation}
      \begin{split}
          {\left\| {f\left( {x + h} \right) - f\left( x \right)} \right\|_Y}& = {\left\| {Df\left( x \right)h + R\left( {x,h} \right)} \right\|_Y} \hfill \\[.2cm]
           &\leqslant {\left\| {Df\left( x \right)h} \right\|_Y} + {\left\| {R\left( {x,h} \right)} \right\|_Y} \hfill \\[.2cm]
           &\leqslant {\left\| {Df\left( x \right)} \right\|_{B\left( {X,Y} \right)}}{\left\| h \right\|_X} + {\left\| {R\left( {x,h} \right)} \right\|_Y}.
      \end{split}
    \end{equation}
    The RHS tends to $0$ as $h \to 0$ in $X$. \cg Since $Df(x)$ is bounded, the first term on the right tends to zero trivially as $h \to 0$. Since $R(x,h)$ is $o(\|h\|)$, it means that $R(x,h)$ goes to zero faster than $h$ goes to zero. This implies, however, that if $h\to 0$, then also $R(x, h) \to 0$. A somewhat obvious fact. \cbk 
  \end{proof}
  Having differentiability, namely \textit{strong} differentiability, at a point $x$ is more than enough to conclude that $f$ is continuous at $x$. A piecewise linear function may be continuous, but not differentiable at the interface points. Strong differentiability allows us to conclude more: 
  \begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
    \begin{lemma}[Local Lipschitz Property]
      If $f:U \to Y$ is differentiable at $x \in U$, then for every $\ve > 0$, there exists a $\delta = \delta(x, \ve) > 0$ such that for every $h$ with $\|h\|_X \leq \delta$, 
      \[{\left\| {f\left( {x + h} \right) - f\left( x \right)} \right\|_Y} \leqslant \left( {{{\left\| {Df\left( x \right)} \right\|}_{B\left( {X,Y} \right)}} + \varepsilon } \right){\left\| h \right\|_X}.\]
    \end{lemma} 
  \end{tcolorbox}
  \begin{proof}
    We have 
    \begin{equation}
      f\left( {x + h} \right) - f\left( x \right) = Df\left( x \right)h + R\left( {x,h} \right).
    \end{equation}
    Since the remainder is $o(\|h\|)$, then for every $\ve > 0$, there exists a $\delta > 0$ such that 
    \begin{equation}
      \frac{{{{\left\| {R\left( {x,h} \right)} \right\|}_Y}}}{{{{\left\| h \right\|}_X}}} < \ve
    \end{equation}
    whenever $\|h\|_X < \delta$. \cg Definition of convergence of $\|R\| /\|h\| \to 0$. \cbk It follows then that 
    \begin{equation}
      {\left\| {f\left( {x + h} \right) - f\left( x \right)} \right\|_Y} = \left\| {Df\left( x \right)h + R\left( {x,h} \right)} \right\| \leqslant {\left\| {Df\left( x \right)} \right\|_{B\left( {X,Y} \right)}}{\left\| h \right\|_X} + \varepsilon {\left\| h \right\|_X}.
    \end{equation}
  \end{proof}
  Even if $f$ is not strongly differentiable, it may still admit some kind of weaker derivative. The key here is that in the Fr\'echet derivative, we require the remainder goes to zero for all paths that take $\|h\|_X \to 0$. We now consider incrementing only in a specific direction $h$. Start with $f:U \to Y$, fix a direction $h \in X$, and consider the auxillary function 
  \begin{equation}
    g:\R \ni t \to g(t) := f(x + th) \in Y.
  \end{equation}



  \begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
    \begin{prop}
      \[f\text{ is Fr\'echet differentiable at }x \implies f\text{ is Gateaux differentiable at }x. \]
    \end{prop}
  \end{tcolorbox}

  \begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
    \begin{theorem}[Chain Rule]
      Let $X, Y, Z$ be NLS's and $U\subset X$, $V\subset Y$ open, $f : U \to Y$ and $g : V \to Z$. Let $x \in U$ and $y = f(x) \in V$. Suppose that $g$ is Fr\'echet differentiable at $y$ and $f$ is Gateaux (or Fr\'echet) differentiable at $x$. Then the composition $g \circ f$ is Gateaux (or Fr\'echet) differentiable at $x$ with 
      \[D(g\circ f)(x) = Dg(y) \circ Df(x)\]
    \end{theorem}
  \end{tcolorbox}

  \begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
    \begin{prop}[Mean Value Theorem for Curves]
      Let $Y$ be an NLS and $\varphi : [a,b] \to Y$ be continuous, where $a < b$ are real numbers. Suppose $\varphi ' (t)$ exists on $(a,b)$ and $\|\varphi'(t)\|_{B(\R,Y)} \leq M$. Then 
      \[\|\varphi(b) - \varphi(a)\|_Y \leq M(b-a).\]
    \end{prop}
  \end{tcolorbox}
  \begin{proof}
    Use a compactness argument. 
  \end{proof}

  \begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
    \begin{theorem}[Mean Value Theorem]
      Let $X,Y$ be NLS's, $U\subset X$ open. Let $f: U \to Y$ be Fr\'echet differentiable at all $x \in U$, and suppose that the line segment 
      \[\ell = \left\{ tx_2 + (1-t)x_1 : t\in [0,1]\right\} \]
      is contained in $U$. Then 
      \[{\left\| {f\left( {{x_2}} \right) - f\left( {{x_1}} \right)} \right\|_Y} \leqslant \mathop {\sup }\limits_{x \in \ell } {\left\| {Df\left( x \right)} \right\|_{B\left( {X,Y} \right)}}{\left\| {{x_2} - {x_1}} \right\|_X}.\]
    \end{theorem}
  \end{tcolorbox}
  \begin{proof}
    Use the MVT for curves applied to the function $\varphi : [0,1]\to Y$, 
    \[\varphi \left( t \right) = f\left( {\left( {1 - t} \right){x_1} + t{x_2}} \right) = f\left( {{x_1} + t\left( {{x_2} - {x_1}} \right)} \right) = f\left( {\gamma \left( t \right)} \right).\]
  \end{proof}

  \begin{definition}
    Let $x$  
  \end{definition}

  \begin{tcolorbox}[colback=red!5!white,colframe=red!75!black]
    \begin{prop}
      Let $X = X_1 \oplus \dots \oplus X_m$ be the direct sum of NLS's, $U\subset X$ open, and $F : U \to Y$. 
    \end{prop}
  \end{tcolorbox}








\subsection{Fixed Points and Contractive Maps}



\subsection{Nonlinear Equations}





\subsection{Higher Derivatives}





\subsection{Extrema}





\subsection{Euler-Lagrange Equations}





\subsection{Constrained Extrema and Lagrange Multipliers}





\end{document}
 